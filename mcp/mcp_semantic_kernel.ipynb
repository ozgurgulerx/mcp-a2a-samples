{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b589347",
   "metadata": {},
   "source": [
    "# MCP in SEMANTIC KERNEL \n",
    "\n",
    "\n",
    "Semantic Kernel (SK) is Microsoft’s open-source SDK for building AI applications with orchestration, memory, and plugin capabilities. As of 2025, SK has introduced **first-class MCP support**, empowering developers to use MCP in their applications in two main ways: **as an MCP client (host)** and as an **MCP server**. This means SK can both *consume* MCP-exposed tools and *expose* SK’s own functions as tools to other agents.\n",
    "\n",
    "SK can not only consume tools, but also **serve tools to others** using MCP. In scenarios where you have built useful functions or business logic as SK plugins, you might want to expose them so that *other* AI agents or applications (not using SK) can call them. By turning SK into an MCP server, you effectively make your SK functions accessible to the wider AI ecosystem.\n",
    "\n",
    "As an **MCP client**, SK points at any MCP endpoint, auto-downloads the tool catalog, wraps each tool as a KernelFunction, and added to kernel as Plugins. So that it lets your LLM call them with normal function-calling syntax. So the *tools* (not the client itself) become first-class SK functions, letting the kernel treat an MCP server as a plug-and-play “toolbox.” Thereafter, when the kernel’s AI model needs to call a function, it can call these MCP-provided functions as if they were local – SK handles the forwarding of the call to the MCP server and returns the result. (**You can think of an MCP server as a dynamic plugin provider.**)\n",
    "\n",
    "**Why it matters**\n",
    "* **Interoperability:** Any MCP-compliant server (GitHub, Salesforce, your own micro-service) can be surfaced to an LLM with zero glue code beyond the wrapper call.\n",
    "* **Composability:** Once wrapped, MCP tools can chain with regular SK prompts, memories, or other plugins, enabling complex agent flows.\n",
    "* **Future-proofing:** As new MCP servers appear, you only swap the endpoint—the SK integration remains unchanged.\n",
    "\n",
    "In that sense Semantic Kernel (SK) can wear both hats. \n",
    "\n",
    "Azure Documentation on SK so far...\n",
    "- 2506 MCP in Azure MCP Server Documentation [link](https://learn.microsoft.com/en-us/azure/developer/azure-mcp-server/)\n",
    "- 2504 Semantic Kernel adds Model Context Protocol (MCP) support for Python [link](https://devblogs.microsoft.com/semantic-kernel/semantic-kernel-adds-model-context-protocol-mcp-support-for-python/#:~:text=We%20are%20excited%20to%20announce,share%20context%20and%20capabilities%20seamlessly)\n",
    "- 2503 Model Context Protocol (MCP): Integrating Azure OpenAI for Enhanced Tool Integration and Prompting [link](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/model-context-protocol-mcp-integrating-azure-openai-for-enhanced-tool-integratio/4393788)\n",
    "- 2503 Integrating MCP Tools with Semantic Kernel: A Step-by-Step Guide [link](https://devblogs.microsoft.com/semantic-kernel/integrating-model-context-protocol-tools-with-semantic-kernel-a-step-by-step-guide/#:~:text=,the%20standardized%20Model%20Context%20Protocol)\n",
    "connecting an AI model to an MCP tool via function calling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
